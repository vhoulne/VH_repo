{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['MT.PA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2023-03-03 -> 2025-03-02)')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AXA.PA']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement des données pour AC.PA...\n",
      "Téléchargement des données pour AIR.PA...\n",
      "Téléchargement des données pour MT.PA...\n",
      "Téléchargement des données pour AXA.PA...\n",
      "Téléchargement des données pour BNP.PA...\n",
      "Téléchargement des données pour EN.PA...\n",
      "Téléchargement des données pour CAP.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement des données pour CA.PA...\n",
      "Téléchargement des données pour ACA.PA...\n",
      "Téléchargement des données pour BN.PA...\n",
      "Téléchargement des données pour DSY.PA...\n",
      "Téléchargement des données pour ENGI.PA...\n",
      "Téléchargement des données pour EL.PA...\n",
      "Téléchargement des données pour RMS.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement des données pour KER.PA...\n",
      "Téléchargement des données pour OR.PA...\n",
      "Téléchargement des données pour LR.PA...\n",
      "Téléchargement des données pour MC.PA...\n",
      "Téléchargement des données pour ML.PA...\n",
      "Téléchargement des données pour ORA.PA...\n",
      "Téléchargement des données pour RI.PA...\n",
      "Téléchargement des données pour STLA.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1 Failed download:\n",
      "['STLA.PA']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement des données pour PUB.PA...\n",
      "Téléchargement des données pour RNO.PA...\n",
      "Téléchargement des données pour SAF.PA...\n",
      "Téléchargement des données pour SGO.PA...\n",
      "Téléchargement des données pour SAN.PA...\n",
      "Téléchargement des données pour SU.PA...\n",
      "Téléchargement des données pour GLE.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement des données pour SW.PA...\n",
      "Téléchargement des données pour TEP.PA...\n",
      "Téléchargement des données pour TTE.PA...\n",
      "Téléchargement des données pour URW.PA...\n",
      "Téléchargement des données pour VIE.PA...\n",
      "Téléchargement des données pour DG.PA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement des données pour VIV.PA...\n",
      "Téléchargement des données pour WLN.PA...\n",
      "Téléchargement terminé.\n",
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "\n",
    "# Définir la période de récupération des données\n",
    "end_date = datetime.datetime.today()\n",
    "start_date = end_date - datetime.timedelta(days=2*365)\n",
    "\n",
    "# Liste des tickers du CAC40 au format Yahoo Finance\n",
    "cac40_tickers = [\n",
    "    \"AC.PA\",   # Accor\n",
    "    \"AIR.PA\",  # Airbus\n",
    "    \"MT.PA\",   # ArcelorMittal\n",
    "    \"AXA.PA\",  # AXA\n",
    "    \"BNP.PA\",  # BNP Paribas\n",
    "    \"EN.PA\",   # Bouygues\n",
    "    \"CAP.PA\",  # Capgemini\n",
    "    \"CA.PA\",   # Carrefour\n",
    "    \"ACA.PA\",  # Crédit Agricole\n",
    "    \"BN.PA\",   # Danone (vérifiez le ticker, cela peut varier)\n",
    "    \"DSY.PA\",  # Dassault Systèmes\n",
    "    \"ENGI.PA\", # Engie\n",
    "    \"EL.PA\",   # EssilorLuxottica\n",
    "    \"RMS.PA\",  # Hermès\n",
    "    \"KER.PA\",  # Kering\n",
    "    \"OR.PA\",   # L'Oréal\n",
    "    \"LR.PA\",   # Legrand\n",
    "    \"MC.PA\",   # LVMH\n",
    "    \"ML.PA\",   # Michelin\n",
    "    \"ORA.PA\",  # Orange\n",
    "    \"RI.PA\",   # Pernod Ricard\n",
    "    \"STLA.PA\", # Stellantis (issu de la fusion PSA/Fiat)\n",
    "    \"PUB.PA\",  # Publicis Groupe\n",
    "    \"RNO.PA\",  # Renault\n",
    "    \"SAF.PA\",  # Safran\n",
    "    \"SGO.PA\",  # Saint-Gobain\n",
    "    \"SAN.PA\",  # Sanofi\n",
    "    \"SU.PA\",   # Schneider Electric\n",
    "    \"GLE.PA\",  # Société Générale\n",
    "    \"SW.PA\",   # Sodexo\n",
    "    \"TEP.PA\",  # Teleperformance\n",
    "    \"TTE.PA\",  # TotalEnergies\n",
    "    \"URW.PA\",  # Unibail-Rodamco-Westfield\n",
    "    \"VIE.PA\",  # Veolia Environnement\n",
    "    \"DG.PA\",   # Vinci\n",
    "    \"VIV.PA\",  # Vivendi\n",
    "    \"WLN.PA\"   # Worldline\n",
    "]\n",
    "\n",
    "data = {}\n",
    "\n",
    "# Boucle sur chaque ticker pour télécharger et sauvegarder les données\n",
    "for ticker in cac40_tickers:\n",
    "    print(f\"Téléchargement des données pour {ticker}...\")\n",
    "    df = yf.download(ticker, start=start_date.strftime(\"%Y-%m-%d\"), end=end_date.strftime(\"%Y-%m-%d\"))\n",
    "    data[ticker] = df\n",
    "\n",
    "\n",
    "print(\"Téléchargement terminé.\")\n",
    "print(len(cac40_tickers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessus j'ai téléchargé le cours des actions du cac40 sur les deux dernières années en utilisant yahou finance. Je n'ai réussi à télécharger que 37 actions sur 40 et j'ai travaillé sur celles-ci.\n",
    "\n",
    "# fonction génératrice du signal d'achat\n",
    "\n",
    "j'ai fait le choix de travailler sur les valeurs en clôture du marché. Après beaucoup d'essais, les durées fonctionant le mieux pour mon algorithme des moyennes mobiles sont de 2 et 5 jours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AC.PA': 'vendre', 'AIR.PA': 'acheter', 'MT.PA': 'Pas assez de données pour le calcul', 'AXA.PA': 'Pas assez de données pour le calcul', 'BNP.PA': 'vendre', 'EN.PA': 'vendre', 'CAP.PA': 'vendre', 'CA.PA': 'vendre', 'ACA.PA': 'ne rien faire', 'BN.PA': 'acheter', 'DSY.PA': 'vendre', 'ENGI.PA': 'vendre', 'EL.PA': 'vendre', 'RMS.PA': 'vendre', 'KER.PA': 'vendre', 'OR.PA': 'acheter', 'LR.PA': 'vendre', 'MC.PA': 'vendre', 'ML.PA': 'ne rien faire', 'ORA.PA': 'vendre', 'RI.PA': 'vendre', 'STLA.PA': 'Pas assez de données pour le calcul', 'PUB.PA': 'vendre', 'RNO.PA': 'vendre', 'SAF.PA': 'vendre', 'SGO.PA': 'acheter', 'SAN.PA': 'acheter', 'SU.PA': 'acheter', 'GLE.PA': 'vendre', 'SW.PA': 'acheter', 'TEP.PA': 'vendre', 'TTE.PA': 'vendre', 'URW.PA': 'vendre', 'VIE.PA': 'vendre', 'DG.PA': 'vendre', 'VIV.PA': 'acheter', 'WLN.PA': 'ne rien faire'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_signal(df, target_date):\n",
    "    \"\"\"\n",
    "    Pour un DataFrame df contenant une colonne 'Close' avec les cours de clôture,\n",
    "    calcule la moyenne mobile sur 2 jours et sur 5 jours pour un jour donné (target_date)\n",
    "    et renvoie un signal :\n",
    "      - \"acheter\" si MA2 > MA5+ 0.05,\n",
    "      - \"vendre\" si MA2 < MA5-0.05,\n",
    "      - \"ne rien faire\" sinon.\n",
    "      \n",
    "    Si le DataFrame ne contient pas suffisamment de données, la fonction renvoie un message d'erreur.\n",
    "    \"\"\"\n",
    "    # S'assurer que l'index est de type datetime\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    \n",
    "    # Filtrer le DataFrame jusqu'au target_date (inclus)\n",
    "    df_target = df.loc[:target_date].copy()\n",
    "    \n",
    "    # Vérifier qu'il y a au moins 5 jours de données pour le calcul\n",
    "    if len(df_target) < 5:\n",
    "        return \"Pas assez de données pour le calcul\"\n",
    "    \n",
    "    # Calcul des moyennes mobiles\n",
    "    df_target[\"MA7\"] = df_target[\"Close\"].rolling(window=2).mean()                                   # c'est ça qu'on peut modifier\n",
    "    df_target[\"MA21\"] = df_target[\"Close\"].rolling(window=5).mean()                                       # 2/5\n",
    "    \n",
    "    # Récupérer les moyennes mobiles du jour target_date (la dernière ligne du DataFrame filtré)\n",
    "    latest = df_target.iloc[-1]\n",
    "    ma7 = latest[\"MA7\"]\n",
    "    ma21 = latest[\"MA21\"]\n",
    "    \n",
    "    # Si ce sont des Series, extraire la valeur scalaire\n",
    "    if isinstance(ma7, pd.Series):\n",
    "        ma7 = ma7.iloc[-1]\n",
    "    if isinstance(ma21, pd.Series):\n",
    "        ma21 = ma21.iloc[-1]\n",
    "    \n",
    "    # Vérifier que les moyennes ne sont pas NaN\n",
    "    if pd.isna(ma7) or pd.isna(ma21):\n",
    "        return \"Données insuffisantes pour le calcul\"\n",
    "    \n",
    "    # Comparaison des moyennes mobiles pour générer le signal\n",
    "    if ma7 > ma21 + 0.01:                                           # j'ai mis le seuil pour ne rien faire + ou - 1 %, cela peut être modifié\n",
    "        return \"acheter\"\n",
    "    elif ma7 < ma21- 0.01:\n",
    "        return \"vendre\"\n",
    "    else:\n",
    "        return \"ne rien faire\"\n",
    "\n",
    "def signals_for_all(data, target_date):\n",
    "    \"\"\"\n",
    "    Applique la fonction generate_signal à chaque action présente dans le dictionnaire data,\n",
    "    et retourne un dictionnaire avec pour clé le ticker et pour valeur le signal.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: dictionnaire où chaque clé est un ticker (ex. \"AC.PA\") et chaque valeur est un DataFrame\n",
    "            contenant les données historiques de l'action.\n",
    "    - target_date: date (string ou datetime) pour laquelle calculer le signal (ex. \"2023-12-31\").\n",
    "    \"\"\"\n",
    "    signals = {}\n",
    "    for ticker, df in data.items():\n",
    "        signals[ticker] = generate_signal(df, target_date)\n",
    "    return signals\n",
    "\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "target_date = \"2023-12-31\"  # date cible\n",
    "result = signals_for_all(data, target_date)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme de gestion du portefeuille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def trading(data, debut, fin, budget):\n",
    "    cash = budget\n",
    "    portfolio = {}  # Clé: ticker, Valeur: nombre d'actions détenues\n",
    "    \n",
    "    # Convertir les dates en datetime\n",
    "    debut_dt = pd.to_datetime(debut)\n",
    "    fin_dt = pd.to_datetime(fin)\n",
    "    \n",
    "    # Vu qu'on travaille avec close (on achète avec le signal du jour précédent)\n",
    "    signal = signals_for_all(data, debut_dt)\n",
    "    \n",
    "    # Les ordres s'exécutent à partir du jour suivant\n",
    "    days = pd.date_range(start=debut_dt + pd.Timedelta(days=1), end=fin_dt, freq='D')\n",
    "    \n",
    "    i=0\n",
    "    for day in days:\n",
    "        # Première étape : Achat\n",
    "        # Pour chaque ticker dont le signal est \"acheter\", on essaie d'acheter au prix d'ouverture du jour courant\n",
    "        achat_effectue = True\n",
    "        while achat_effectue:\n",
    "            achat_effectue = False\n",
    "            for ticker, s in signal.items():\n",
    "                if s == \"acheter\":\n",
    "                    try:\n",
    "                        open_price = data[ticker].loc[day, \"Open\"]\n",
    "                        if isinstance(open_price, pd.Series):\n",
    "                            open_price = open_price.iloc[0]\n",
    "                    except Exception:\n",
    "                        i+=1\n",
    "                        continue  # Si aucune donnée pour ce jour, passe au suivant\n",
    "                    \n",
    "                    if cash >= open_price:\n",
    "                        cash -= open_price\n",
    "                        portfolio[ticker] = portfolio.get(ticker, 0) + 1\n",
    "                        achat_effectue = True\n",
    "        \n",
    "        # Deuxième étape : Vente\n",
    "        # Pour chaque ticker dont le signal est \"vendre\", on vend toutes les actions détenues\n",
    "        for ticker, s in signal.items():\n",
    "            if s == \"vendre\" and portfolio.get(ticker, 0) > 0:\n",
    "                try:\n",
    "                    open_price = data[ticker].loc[day, \"Open\"]\n",
    "                    if isinstance(open_price, pd.Series):\n",
    "                        open_price = open_price.iloc[0]\n",
    "                except Exception:\n",
    "                    continue\n",
    "                cash += portfolio[ticker] * open_price\n",
    "                portfolio[ticker] = 0\n",
    "        \n",
    "        # Mise à jour du signal pour le jour suivant (utilisation des données de clôture du jour courant)\n",
    "        signal = signals_for_all(data, day)\n",
    "    print(\"nombre de valeurs auxquelles on n'a pas accès  : \",i,\"\\n nombre total de valeurs : \",365*37)\n",
    "    return cash, portfolio\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application et résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de valeurs auxquelles on n'a pas accès  :  3618 \n",
      " nombre total de valeurs :  13505\n",
      "Cash final : 66.3826272216925\n",
      "Portefeuille final : {'AIR.PA': 0, 'EN.PA': 1, 'CA.PA': 1, 'BN.PA': 1, 'ENGI.PA': 25, 'KER.PA': 1, 'LR.PA': 0, 'ORA.PA': 1, 'SAN.PA': 11, 'SU.PA': 0, 'WLN.PA': 1, 'OR.PA': 0, 'DSY.PA': 0, 'AC.PA': 1, 'BNP.PA': 1, 'CAP.PA': 29, 'ACA.PA': 1, 'EL.PA': 1, 'VIV.PA': 3, 'ML.PA': 0, 'RNO.PA': 36, 'RI.PA': 0, 'PUB.PA': 0, 'SGO.PA': 0, 'SAF.PA': 0, 'GLE.PA': 0, 'SW.PA': 20, 'TTE.PA': 0, 'VIE.PA': 1, 'DG.PA': 0, 'RMS.PA': 0, 'TEP.PA': 0, 'URW.PA': 11, 'MC.PA': 0}\n"
     ]
    }
   ],
   "source": [
    "cash_final, portefeuille_final = trading(data, \"2023-01-01\", \"2024-12-31\", 10000)\n",
    "print(\"Cash final :\", cash_final)\n",
    "print(\"Portefeuille final :\", portefeuille_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/!\\ les journées manquantes correspondent aux jours fériés et aux weekend. Le cac40 est alors fermé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approximation\n",
      "approximation\n",
      "approximation\n"
     ]
    }
   ],
   "source": [
    "def get_closing_prices(data, t):\n",
    "    \"\"\"\n",
    "    Retourne un dictionnaire contenant pour chaque ticker du dictionnaire `data`\n",
    "    le prix de clôture (float) disponible à la date t.\n",
    "    \n",
    "    Pour chaque ticker, si la date t est présente dans l'index, la fonction renvoie\n",
    "    la valeur de la colonne \"Close\". Sinon, elle renvoie la dernière valeur disponible avant t.\n",
    "    Si aucune donnée n'est disponible, la valeur sera None.\n",
    "    \"\"\"\n",
    "    closing_prices = {}\n",
    "    t = pd.to_datetime(t)\n",
    "    \n",
    "    for ticker, df in data.items():\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        # Vérifier si t est exactement dans l'index\n",
    "        if t in df.index:\n",
    "            price = df.loc[t, \"Close\"]\n",
    "            if isinstance(price, pd.Series):  # Si plusieurs valeurs, en prendre la première\n",
    "                price = price.iloc[0]\n",
    "        else:\n",
    "            print(\"approximation\")\n",
    "            df_filtered = df.loc[:t]\n",
    "            if not df_filtered.empty:\n",
    "                price = df_filtered.iloc[-1][\"Close\"]\n",
    "            else:\n",
    "                price = None\n",
    "        closing_prices[ticker] = float(price) if price is not None else None       \n",
    "    return closing_prices\n",
    "\n",
    "\n",
    "# Valeur des actions à la date de fin\n",
    "t = \"2024-12-31\"\n",
    "prix_cloture = get_closing_prices(data, t)\n",
    "\n",
    "# # Afficher uniquement le ticker et le prix\n",
    "# for ticker, price in prix_cloture.items():\n",
    "#     print(f\"{ticker}: {price}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 approximations c'est ok par rapport au nombre de valeurs calculées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10902.972067567456\n"
     ]
    }
   ],
   "source": [
    "value_portfolio = 0\n",
    "for clef in portefeuille_final:\n",
    "    #print(clef)\n",
    "    try:\n",
    "        value_portfolio+=prix_cloture[clef] * portefeuille_final[clef]\n",
    "    except:\n",
    "        print(clef,\"wtf\")\n",
    "\n",
    "print(cash_final+value_portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 2024 : -1.8 % je surperforme le cac40 qui a fait -2.1 %!\n",
    "- 2023:   + 12.5 %, je sousperforme le marché qui a fait +15%\n",
    "- sur deux ans, je sousperforme le marché mais fait quand même +9%.\n",
    "- Mon algorithme minimise le risque en essayant d'investir sur des actions différentes au maximum ce qui correspondrait au fait de sous-performé le marché en hausse et de surperformé le marché en baisse.\n",
    "- vois d'amélioration : prendre en compte les dividendes, utiliser une matrice de covariance pour encore plus minimiser le risque, ne pas investir sur une action dès qu'elle est en hausse mais plutôt investir seulement sur les \"meilleurs\" actions.\n",
    "\n",
    "- Par ailleurs, j'ai testé de prédire les prix avec du deep learning et de faire un algorithme dessus et étonnament, pour chaque action, l'IA prédit l'évolution moyenne du marché de l'année divisée par le nombre de jour. Par conséquent, l'IA propose juste de suivre l'indice du cac40... Ce qui perd un peu son sense quand l'on cherche à battre le marché.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
